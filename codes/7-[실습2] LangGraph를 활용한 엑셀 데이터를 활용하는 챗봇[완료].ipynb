{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습2] LangGraph를 활용한 엑셀 데이터를 활용하는 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "---\n",
    "1. LangGraph를 활용해서 사용자의 질문에 따라 질문에 바로 답하거나, 엑셀 데이터를 활용해서 답하는 챗봇을 만들어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목차\n",
    "---\n",
    "\n",
    "1. **엑셀 데이터를 활용하는 챗봇:** LangGraph를 활용해서 엑셀 데이터를 선택적으로 활용하는 챗봇을 구성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 개요\n",
    "---\n",
    "LangChain을 활용해서 자연어로 데이터를 분석할 수 있는 챗봇을 구현하고 사용해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 환경 설정\n",
    "- 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ollama를 통해 Mistral 7B 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[?25h\n",
      "Error: open /mnt/elice/dataset/blobs/sha256-491dfa501e59ed17239711477601bdc7f559de5407fbd4a2a79078b271045621-partial-0: read-only file system\n"
     ]
    }
   ],
   "source": [
    "!ollama pull mistral:7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 엑셀 데이터를 활용하는 챗봇\n",
    "- LangGraph를 활용해서 엑셀 데이터를 선택적으로 활용하는 챗봇을 구성합니다.\n",
    "- 이번 실습에 사용할 데이터는 2일차 실습 중 **Langchain을 이용한 머신러닝 기반 데이터 분석 실무 프로젝트** 에 사용하는 데이터입니다.\n",
    " \n",
    "저희는 이전 실습에서 원하는 데이터를 자연어로 입력하면, 이를 바탕으로 자동으로 코드를 생성하고 결과를 반환하는 체인을 구성했습니다. \n",
    "\n",
    "여기서 더 나아가서, LangGraph를 활용해서 엑셀 데이터를 선택적으로 활용한 후 자연어로 대답하는 챗봇을 만들어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, mistral:7b 모델을 사용하는 ChatOllama 객체를 생성하고, 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"mistral:7b\")\n",
    "\n",
    "# 데이터를 불러오고, 이름과 컬럼명을 저장합니다.\n",
    "data_dir = './data'\n",
    "df_inkjet = pd.read_csv(os.path.join(data_dir, 'InkjetDB_preprocessing.csv'), index_col=0)\n",
    "\n",
    "# 데이터를 저장한 변수명을 LLM에 제공하여 이 변수를 활용하는 코드를 작성하게 할 수 있습니다.\n",
    "df_name = \"df_inkjet\"\n",
    "df_columns = \", \".join(df_inkjet.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 실습에서 사용한 코드를 파싱하고 실행하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM이 생성한 코드를 파싱하는 함수를 정의합니다.\n",
    "def python_code_parser(input: str) -> str:\n",
    "    # LLM은 대부분 ``` 블럭 안에 코드를 출력합니다. 이를 활용합니다.\n",
    "    # ```python (코드) ```, 혹은 ``` (코드) ``` 형태로 출력됩니다. 두 경우 모두에 대응하도록 코드를 작성합니다.\n",
    "    processed_input = input.replace(\"```python\", \"```\").strip()\n",
    "    parsed_input_list = processed_input.split(\"```\")\n",
    "\n",
    "    # 만약 ``` 블럭이 없다면, 입력 텍스트 전체가 코드라고 간주합니다.\n",
    "    # 아닐 경우 이어지는 코드 실행 과정에서 예외 처리를 통해 오류를 확인할 수 있습니다.\n",
    "    if len(parsed_input_list) == 1:\n",
    "        return processed_input\n",
    "\n",
    "    # 코드 부분만 추출합니다. \n",
    "    # LLM은 여러 코드 블럭에 걸쳐 필요한 코드를 출력할 수 있으므로, 코드가 있는 홀수 번째 텍스트를 모두 저장합니다.\n",
    "    parsed_code_list = []\n",
    "    for i in range(1, len(parsed_input_list), 2):\n",
    "        parsed_code_list.append(parsed_input_list[i])\n",
    "    \n",
    "    # 코드 부분을 하나로 합칩니다.\n",
    "    return \"\\n\".join(parsed_code_list)\n",
    "\n",
    "# 생성한 코드를 실행하는 함수를 정의합니다.\n",
    "def run_code(input_code: str):\n",
    "    # 코드가 출력한 값을 캡쳐하기 위한 StringIO 객체를 생성합니다.\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        # Redirect stdout to the StringIO object\n",
    "        with contextlib.redirect_stdout(output):\n",
    "            # Python 3.10 버전이므로, 키워드 인자를 사용할 수 없습니다.\n",
    "            # 코드가 실행하면서 출력한 모든 결과를 캡쳐합니다.\n",
    "            exec(input_code, {\"df_inkjet\": df_inkjet})\n",
    "    except Exception as e:\n",
    "        # 에러가 발생할 경우, 이를 StringIO 객체에 저장합니다.\n",
    "        print(f\"Error: {e}\", file=output)\n",
    "    # StringIO 객체에 저장된 값을 반환합니다.\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(question: str) -> str:\n",
    "    \"\"\"입력한 질문을 위한 데이터 쿼리 코드를 생성하여 실행한 후 결과를 반환하는 Tool.\"\"\"\n",
    "        # 프롬프트를 정의합니다.\n",
    "    system_message = \"당신은 주어진 데이터를 분석하는 데이터 분석가입니다.\\n\"\n",
    "    system_message += f\"주어진 DataFrame에서 데이터를 출력하여 주어진 질문에 답할 수 있는 파이썬 코드를 작성하세요. \"\n",
    "    system_message += f\"{df_name} DataFrame에 액세스할 수 있습니다.\\n\"\n",
    "    system_message += f\"`{df_name}` DataFrame에는 다음과 같은 열이 있습니다: {df_columns}\\n\"\n",
    "    system_message += \"데이터는 이미 로드되어 있으므로 데이터 로드 코드를 생략해야 합니다.\"\n",
    "\n",
    "    message_with_data_info = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    "\n",
    "    prompt_with_data_info = ChatPromptTemplate.from_messages(message_with_data_info)\n",
    "\n",
    "    # 체인을 구성합니다.\n",
    "    code_generate_chain = (\n",
    "        {\"question\": RunnablePassthrough()}\n",
    "        | prompt_with_data_info\n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "        | python_code_parser\n",
    "    )\n",
    "    code = code_generate_chain.invoke(question)\n",
    "    answer = run_code(code)\n",
    "    \n",
    "    return {'code': code, 'data': answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습1 과 같이, `State` class를 정의해서 그래프의 각 구성 요소 간에 전달할 정보의 속성을 정의합니다.\n",
    "\n",
    "그리고 `StateGraph` 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # 그래프 상태의 속성을 정의합니다.\n",
    "    # 질문, LLM이 생성한 텍스트, 데이터, 코드를 저장합니다.\n",
    "    question: str #문자열 타입의 질문 내용을 저장합니다.\n",
    "    generation: str #LLM(Large Language Model)이 생성한 텍스트 결과를 문자열로 저장합니다.\n",
    "    data: str #분석 결과와 관련된 데이터를 문자열로 저장합니다.\n",
    "    code: str #실행할 코드를 문자열 형태로 저장합니다.\n",
    "        \n",
    "# 그래프를 구성하기 위해 StateGraph 객체를 생성합니다.\n",
    "# 생성자의 인자로 State를 전달하여 Node 간에 정보를 전달할 때 State type을 사용함을 명시합니다.\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프는 Node와 Edge로 구성되어 있습니다.\n",
    "\n",
    "Node는 체인의 각 구성 요소에 대응합니다. Agent, Tool, LLM 등 그래프의 각 구성 요소를 의미합니다.\n",
    "\n",
    "Edge는 Node를 연결하는 요소로, Node에서 정보를 어느 Node로 전달해야 하는지를 나타냅니다.\n",
    "- 체인은 일렬로 이어져 있기 때문에, 사용자의 입력을 연결된 순서대로 통과시키면 원하는 결과를 얻을 수 있습니다.\n",
    "- 하지만, 그래프는 일렬로 이어져 있지 않기 때문에 Edge를 통해 정보를 전달하는 순서 및 방향을 정해줘야 합니다.\n",
    "\n",
    "이번 실습에서는 조건부로 바로 답변하거나, 데이터를 불러오는 코드를 생성하고 실행한 결과를 바탕으로 답변하는 챗봇을 만들어 볼 것입니다.<br>\n",
    "여기서 조건과 경로를 Edge를 활용해 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node 생성\n",
    "# Node는 그래프에서 실행될 수 있는 작업을 정의합니다.\n",
    "# Node는 함수로 정의되며, StateGraph를 정의할 때 사용한 State type을 입력으로 받습니다.\n",
    "# Node는 state를 업데이트하거나, 새로운 state를 반환할 수 있습니다.\n",
    "def init_answer(state: State) -> str:\n",
    "    \"\"\"\n",
    "    코드 생성 프롬프트를 활용해서, 코드를 생성해야 할지, 그냥 답하면 될 지 결정하고 답변합니다.\n",
    "    이 답변을 활용해서 다른 함수에서 데이터 쿼리를 진행할 지, 바로 답변 생성을 진행할 지 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): LLM의 답변을 포함한 새로운 State\n",
    "    \"\"\"\n",
    "    print(\"---데이터 추출 필요성 확인---\") # 현재 상태를 확인하기 위한 Print문\n",
    "    question = state[\"question\"]\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=\"ollama\",\n",
    "        model=\"mistral:7b\",\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        streaming=True\n",
    "    )\n",
    "    decide_system_message = \"당신은 주어진 데이터를 분석하는 데이터 분석가입니다.\\n\"\n",
    "    decide_system_message += f\"주어진 DataFrame에서 데이터를 출력하여 주어진 질문에 답할 수 있는 파이썬 코드를 작성하세요. \"\n",
    "    decide_system_message += f\"{df_name} DataFrame에 액세스할 수 있습니다.\\n\"\n",
    "    decide_system_message += f\"`{df_name}` DataFrame에는 다음과 같은 열이 있습니다: {df_columns}\\n\"\n",
    "    decide_system_message += \"데이터는 이미 로드되어 있으므로 데이터 로드 코드를 생략해야 합니다.\"\n",
    "    decide_system_message += \"주어진 질문이 데이터와 무관하다면, 파이썬 코드를 생성하지 말고 주어진 질문에 답하세요.\"\n",
    "    decide_user_message = \"{question}\"\n",
    "    decide_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", decide_system_message),\n",
    "        (\"human\", decide_user_message)\n",
    "    ])\n",
    "    \n",
    "    decide_chain = {\"question\": RunnablePassthrough()} | decide_prompt | llm\n",
    "    \n",
    "    generation = decide_chain.invoke(question)  \n",
    "    return {\"question\": question, \"generation\": generation.content}\n",
    "\n",
    "\n",
    "def query(state: State):\n",
    "    \"\"\"\n",
    "    데이터를 쿼리하는 코드를 생성하고, 실행하고, 그 결과를 포함한 State를 반환합니다.\n",
    "    위 과정은 앞서 정의한 `find_data` 함수를 활용합니다.\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): 쿼리한 데이터를 포함한 새로운 State\n",
    "    \"\"\"\n",
    "    print(\"---데이터 쿼리---\") # 현재 상태를 확인하기 위한 Print문\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    data = find_data(question)\n",
    "    return {\"question\": question, \"code\": data['code'], \"data\": data['data'], \"generation\": data['code']}\n",
    "\n",
    "def answer_with_data(state: State):\n",
    "    \"\"\"\n",
    "    쿼리한 데이터를 바탕으로 답변을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): LLM의 답변을 포함한 새로운 State\n",
    "    \"\"\"\n",
    "    print(\"---데이터 기반 답변 생성---\") # 현재 상태를 확인하기 위한 Print문\n",
    "    question = state[\"question\"]\n",
    "    data = state[\"data\"]\n",
    "\n",
    "    # 데이터를 바탕으로 질문에 대답하는 코드를 생성합니다.\n",
    "    reasoning_system_message = \"당신은 데이터를 바탕으로 질문에 답하는 데이터 분석가입니다.\\n\"\n",
    "    reasoning_system_message += f\"사용자가 입력한 데이터를 바탕으로, 질문에 대답하세요.\"\n",
    "\n",
    "    reasoning_user_message = \"데이터: {data}\\n{question}\"\n",
    "\n",
    "    reasoning_with_data = [\n",
    "        (\"system\", reasoning_system_message),\n",
    "        (\"human\", reasoning_user_message),\n",
    "    ]\n",
    "    reasoning_with_data_chain = ChatPromptTemplate.from_messages(reasoning_with_data) | llm | StrOutputParser()\n",
    "    \n",
    "    # 대답 생성\n",
    "    generation = reasoning_with_data_chain.invoke({\"data\": data, \"question\": question})\n",
    "    return {\"question\": question, \"code\": state['code'], \"data\": data, \"generation\": generation}\n",
    "\n",
    "\n",
    "    \n",
    "def answer(state: State):\n",
    "    \"\"\"\n",
    "    데이터를 쿼리하지 않고 답변을 바로 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 그래프 상태\n",
    "\n",
    "    Returns:\n",
    "        state (dict): LLM의 답변을 포함한 새로운 State\n",
    "    \"\"\"\n",
    "    print(\"---답변 생성---\") # 현재 상태를 확인하기 위한 Print문\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    return {\"question\": question, \"generation\": llm.invoke(question).content}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init_answer 함수의 시스템 프롬프트를 확인해보면, '주어진 질문이 데이터와 무관하다면, 파이썬 코드를 생성하지 말고 주어진 질문에 답하세요.' 라는 문장이 있습니다.\n",
    "\n",
    "이는 데이터과 유관한 질문을 했을 경우 코드를 생성하고, 그렇지 않다면 일반 답변을 생성하도록 유도하는 프롬프트입니다.\n",
    "- 여기서 생성된 답변을 바로 출력하거나 사용하지 않는 이유는, 두 경우에 모두 대응하기 위해 시스템 프롬프트를 불필요하게 길게 설정하여 전체적인 답변의 퀄리티가 떨어지기 떄문입니다.\n",
    "\n",
    "즉, 코드가 생성되어 ```python 으로 시작한 블럭이 있다면 코드 생성 분기로 넘기고, 그렇지 않다면 단순 답변 분기로 넘기면 될 것입니다.\n",
    "\n",
    "`decide_query` 함수를 통해 이 로직을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'decide_query' 함수 정의: 'state'라는 딕셔너리 형태의 인자를 받아서 처리하고\n",
    "# 조건에 따라 \"query\" 또는 \"answer\" 문자열을 반환하는 함수입니다.\n",
    "def decide_query(state: State) -> str:\n",
    "    \n",
    "    # state 딕셔너리에서 \"generation\" 키에 해당하는 값을 가져옴\n",
    "    # 이 값은 어떤 모델 또는 시스템이 생성한 응답일 것으로 추정됨\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    # 응답된 generation 값을 콘솔에 출력하여 디버깅 및 확인용으로 사용\n",
    "    print(f\"Response: {generation}\")\n",
    "    \n",
    "    # 만약 generation 문자열 내에 \"```python\"이라는 코드 블록이 포함되어 있는 경우\n",
    "    # (대소문자 구분 없이 검색하기 위해 .lower() 메서드를 사용)\n",
    "    if \"```python\" in generation.lower():\n",
    "        # \"query\"라는 문자열을 반환하여 해당 노드로 이동\n",
    "        return \"query\"  # \"query\" 노드로 이동\n",
    "\n",
    "    # 위 조건이 만족되지 않는 경우 (즉, 코드 블록이 포함되지 않은 경우)\n",
    "    else:\n",
    "        # \"answer\"라는 문자열을 반환하여 해당 노드로 이동\n",
    "        return \"answer\"  # \"answer\" 노드로 이동\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 실습과 달리 총 4개의 노드를 사용하고, 조건에 따라 사용하는 노드가 달라집니다.\n",
    "\n",
    "이를 구현하기 위해, 노드와 간선을 그래프에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그래프 구성\n",
    "\n",
    "# 1. 앞서 정의한 각 Node를 그래프에 추가합니다.\n",
    "# Node는 워크플로우의 특정 단계를 의미하며, 각 노드는 함수 또는 처리 로직을 담당합니다.\n",
    "workflow.add_node(\"init_answer\", init_answer)  # 첫 번째 노드, 초기 답변을 처리하는 함수\n",
    "workflow.add_node(\"query\", query)              # 사용자의 질문을 처리하는 노드\n",
    "workflow.add_node(\"answer\", answer)            # 단순한 응답을 처리하는 노드\n",
    "workflow.add_node(\"answer_with_data\", answer_with_data)  # 데이터 기반의 응답을 처리하는 노드\n",
    "\n",
    "# 2. 그래프의 시작 지점을 정의합니다.\n",
    "# 이 워크플로우가 실행될 때 가장 먼저 실행되는 노드를 지정합니다.\n",
    "workflow.set_entry_point(\"init_answer\")  # init_answer 노드가 가장 먼저 실행됩니다.\n",
    "\n",
    "# 3. 그래프의 간선을 정의합니다.\n",
    "# 간선은 노드 간의 순서 및 흐름을 나타냅니다.\n",
    "# END는 해당 경로의 종료를 의미합니다.\n",
    "\n",
    "workflow.add_edge(\"answer\", END)  # answer 노드에서 END로 연결 (answer가 종료 지점)\n",
    "# 위 코드와 동일한 의미: workflow.set_finish_point(\"answer\")\n",
    "\n",
    "workflow.add_edge(\"answer_with_data\", END)  # answer_with_data 노드에서 END로 연결 (종료 지점)\n",
    "workflow.add_edge(\"query\", \"answer_with_data\")  # query 노드가 실행된 후 answer_with_data로 이어집니다.\n",
    "\n",
    "# 4. 조건부 간선을 정의합니다.\n",
    "# 특정 조건에 따라 서로 다른 경로로 이동하도록 설정합니다.\n",
    "# init_answer 노드의 결과에 따라 decide_query 함수가 분기 처리를 수행합니다.\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"init_answer\",  # 조건부 분기의 출발 노드 (init_answer)\n",
    "    decide_query,   # 조건을 평가하는 함수. 결과에 따라 어느 노드로 이동할지 결정합니다.\n",
    "    {\n",
    "        \"query\": \"query\",   # decide_query의 결과가 \"query\"일 경우 query 노드로 이동\n",
    "        \"answer\": \"answer\"  # decide_query의 결과가 \"answer\"일 경우 answer 노드로 이동\n",
    "    }\n",
    ")\n",
    "# 이 조건부 간선은 그래프의 유연성을 높여, 처리 흐름을 상황에 맞게 분기할 수 있도록 도와줍니다.\n",
    "# 결정 로직이 명확해지므로 그래프의 가독성과 유지보수성이 향상됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node, Edge, 분기를 모두 구성했으니 이제 그래프를 컴파일 하고, 그 구조를 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 챗봇을 사용해봅시다. \n",
    "- 예시 질문 (데이터 활용): Velocity가 가장 큰 데이터를 알려줘\n",
    "- 예시 질문 (데이터 무관): 오늘 점심으로 뭐 먹을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무한 루프를 시작합니다. 사용자가 '종료'를 입력하기 전까지 계속 반복합니다.\n",
    "while True:\n",
    "    # 사용자의 질문을 입력받습니다.\n",
    "    question = input(\"질문을 입력해주세요 (종료를 원하시면 '종료'를 입력해주세요.): \")\n",
    "\n",
    "    # 만약 사용자가 '종료'를 입력하면 루프를 종료합니다.\n",
    "    if question == \"종료\":\n",
    "        break\n",
    "    else:\n",
    "        # 사용자가 입력한 질문을 'graph.stream()'에 전달하여 그래프를 실행합니다.\n",
    "        # 'graph'는 Langchain의 StateGraph 객체로, 워크플로우에 따라 여러 노드를 처리합니다.\n",
    "        # stream() 메서드는 노드의 실행 결과를 이벤트로 순차적으로 반환합니다.\n",
    "        for event in graph.stream({\"question\": (\"user\", question)}):\n",
    "            \n",
    "            # 각 이벤트의 결과 값들을 순회합니다.\n",
    "            # event.values()는 실행된 각 노드의 결과를 포함합니다.\n",
    "            for value in event.values():\n",
    "                # 노드의 전체 결과를 출력합니다.\n",
    "                print(value)\n",
    "\n",
    "                # 'generation' 키에 포함된 응답 텍스트를 추출하여 출력합니다.\n",
    "                # 이 값은 AI 모델이 생성한 응답일 가능성이 큽니다.\n",
    "                print(\"Assistant:\", value[\"generation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 invoke가 아닌 stream()을 사용했을까?\n",
    "\n",
    "실시간 피드백 제공\n",
    "\n",
    "스트리밍 방식은 각 노드가 실행되면서 나온 중간 결과를 즉시 반환합니다.\n",
    "챗봇처럼 대화형 시스템에서는 사용자가 질문을 던진 후, 가능한 빨리 응답을 받는 것이 중요합니다. \n",
    "invoke()는 모든 프로세스가 끝난 후 결과를 반환하므로 사용자 대기 시간이 길어질 수 있습니다.\n",
    "\n",
    "복잡한 워크플로 지원\n",
    "\n",
    "질문이 여러 노드를 거치며 처리된다면, 각 노드의 결과를 실시간으로 확인하는 것이 중요할 수 있습니다. \n",
    "예를 들어, AI 모델이 여러 단계를 통해 응답을 생성하거나 외부 API를 호출하는 경우, \n",
    "중간 결과를 보여주는 것이 사용자 경험을 향상시킵니다.\n",
    "\n",
    "대규모 작업 처리에 적합\n",
    "\n",
    "처리 시간이 오래 걸리는 작업의 경우 stream()은 노드가 완료될 때마다 \n",
    "진행 상황을 출력할 수 있어 사용자에게 유용한 정보를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 실습\n",
    "- 현재 프롬프트는 데이터 분석이 필요 없는 일부 질문 (Mistral에 대해 설명해줘 등) 에 대해서도 데이터 분석을 시도하기도 합니다.\n",
    "- 다음 실습에서는 이를 개선해볼 것입니다. 그 전에, 프롬프트를 개선해서 이러한 현상을 완화해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드의 주석을 해제하고 실행하면 본 실습에서 다운받은 모델 파일을 삭제합니다.\n",
    "# 각 실습에서 같은 모델이라도 다시 다운 받기 때문에, \n",
    "# 실습이 종료되었으면 아래 명령어를 실행하여 불필요한 파일을 삭제하는 것이 좋습니다.\n",
    "# !rm -rf .ollama/models/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
